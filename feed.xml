<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://jlxh824.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://jlxh824.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-03-07T14:19:06+00:00</updated><id>https://jlxh824.github.io/feed.xml</id><title type="html">Pui Kuen Leung</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">A few exercises in probability theory</title><link href="https://jlxh824.github.io/blog/2024/math/" rel="alternate" type="text/html" title="A few exercises in probability theory"/><published>2024-03-07T00:00:00+00:00</published><updated>2024-03-07T00:00:00+00:00</updated><id>https://jlxh824.github.io/blog/2024/math</id><content type="html" xml:base="https://jlxh824.github.io/blog/2024/math/"><![CDATA[<p>Here I give a list of seven (in my opinion) very cool and instructive exercises in probability. Only the basics of measure theoretic probability theory and martingales is needed. Most of these are assignment or exam exercises I encountered during my undergraduate studies. They are not supposed to be trivial, yet doable especially with the hints given.</p> <ol> <li> <p>Let \(X_1,X_2,\ldots\) be an iid sequence with \(\mathbb{P}(X_1 \in [m,M])=1\) for some \(0&lt;m&lt;M&lt;\infty\). Show that \(\mathbb{E}(X_2 / X_1) &lt; \infty\) and that \begin{equation}\frac{1}{n} \left( \frac{X_2}{X_1} + \frac{X_3}{X_2}+\cdots+\frac{X_{n+1}}{X_n} \right) \to \mathbb{E}\left(\frac{X_2}{X_1}\right) \end{equation}almost surely as \(n\to\infty\).</p> </li> <li> <p>Let \(X, Y\) be two independent real-valued random variables defined on \((\Omega,\mathcal{F},\mathbb{P})\). Let \(f : \mathbb{R}^2\to\mathbb{R}\) be a bounded Borel function. Show that \begin{equation}\mathbb{E}[f(X,Y)|Y] = \mathbb{E}(f(X,y))|_{y=Y}.\end{equation} Hint: first show the result holds for indicator functions \(f = 1_\Gamma\) where \(\Gamma \in \mathcal{B}(\mathbb{R}^2)\); to do so you may wish to use the \(\pi\)-\(\lambda\) theorem.</p> </li> <li> <p>In this question you are asked to prove the Kolmogorov 0-1 law using martingales. Let \((\Omega,\mathcal{F},\mathbb{P})\) be a probability space.</p> <p>(a) Let \((\mathcal{F}_n)\) be a filtration such that \(\mathcal{F}=\bigcup_n \mathcal{F}_n\). Prove that for all \(f\in L^1(\Omega)\) we have \(\mathbb{E}(f \| \mathcal{F}_n)\to f\) almost surely as \(n\to\infty\).</p> <p>(b) Let \((X_n)\) be independent \(L^1(\Omega)\) random variables. Define \(\mathcal{F}_n := \sigma(X_j : j=0,\ldots,n)\) and \(\mathcal{T}_n :=\sigma(X_j : j\geq n)\). Assume that \(\mathcal{F} = \bigcup_n \mathcal{F}_n\). Consider the tail \(\sigma\)-algebra \(\mathcal{T} = \bigcap_n \mathcal{T}_n\). Prove that for all \(C\in\mathcal{T}\) and for all \(n\), we have that \begin{equation}\mathbb{E}(1_C | \mathcal{F}_n)=\mathbb{P}(C).\end{equation} Deduce that \(\mathbb{P}(C)\in\{0, 1\}\).</p> </li> <li> <p>Let \(\xi_1,\xi_2,\ldots\) be iid random variables defined on a probability space \((\Omega,\mathcal{F},\mathbb{P})\) such that \(\mathbb{P}(\xi_k = 1)=\mathbb{P}(\xi_k=-1)=\frac{1}{2}\) for all \(k\). Let \(\mathcal{F}_n = \sigma(\xi_1,\ldots,\xi_n)\), and let \(S_n = \sum_{k=1}^n \xi_k\). For \(r\in\mathbb{R}\), define \begin{equation}M_n(r)=\exp\left(rS_n-\frac{nr^2}{2}\right),\quad n\geq 1.\end{equation}</p> <p>(a) Show that for every \(r\in\mathbb{R}\) the process \((M_n(r))\) is an \((\mathcal{F}_n)\)-supermartingale.</p> <p>(b) Let \(H_n = \int_\mathbb{R} M_n(r) \,dr.\) Show that \((H_n)\) is an \((\mathcal{F}_n)\)-supermartingale and that \begin{equation}H_n=\sqrt{\frac{2\pi}{n}}e^{S_n^2/2n}.\end{equation}</p> <p>(c) Show that \(H_\infty := \lim_{n\to\infty} H_n\) exists almost surely and deduce that \begin{equation}\sup_{n\geq 1}\frac{1}{\sqrt{n}}e^{S_n^2/2n} &lt; \infty \quad \text{a.s.}\end{equation}</p> <p>(d) Hence prove that \begin{equation} \limsup_{n\to\infty} \frac{|S_n|}{\sqrt{2n\log n}} \leq 1 \quad \text{a.s.} \end{equation}</p> </li> <li> <p>Let \((B_t)_{t\geq 0}\) be a Brownian motion defined on \((\Omega,\mathcal{F},\mathbb{P})\), \(\sigma : \mathbb{R}\to\mathbb{R}\) be bounded and Lipschitz continuous, and \(x_0\in L^2(\Omega)\). Let \((X_n)_{n=1}^\infty\) and \((Y_n)_{n=1}^\infty\) be processes with \(X_j,Y_j\in L^2(\Omega)\) for all \(j\) such that they solve the stochastic difference equation \begin{equation} Z_{n+1}=Z_{n}+\sigma(Z_{n})(B_{n+1}-B_{n}) \text{ for } n=1,2,\ldots,\quad Z_{0}=x_{0}. \end{equation} Prove that \(X_j = Y_j\) almost surely for all \(j\).</p> </li> <li> <p>In this question you are asked to prove Rademacherâ€™s theorem using a probabilistic approach. Consider the probability space \((\Omega,\mathcal{F},\mathbb{P}) = ([0,1),\mathcal{B}([0,1)), \lambda).\) Let \(A_{k,n} = [\frac{k-1}{2^n}, \frac{k}{2^n})\) for \(k=1,\ldots,2^n\) and \(n=0,1,\ldots\)</p> <p>(a) Let \(\mathcal{F}_n := \sigma(A_{k,n} : k\leq 2^n)\). Show that \(\mathcal{F} = \sigma(\bigcup_{n=0}^\infty \mathcal{F}_n)\).</p> <p>(b) For \(n\geq 0\) let \(\xi_n(\omega) := \sum_{k=1}^{2^n}\frac{k-1}{2^n} 1_{A_{k,n}}(\omega)\) and let \(f :[0,1]\to \mathbb{R}\) be a bounded measurable function. Let \begin{equation}X_n(\omega) := \frac{f(\xi_n(\omega)+2^{-n})-f(\xi_n(\omega))}{2^{-n}}.\end{equation} Show that \((X_n)\) is an \((\mathcal{F}_n)\)-martingale.</p> <p>(c) Assume now that \(f:[0,1]\to\mathbb{R}\) is Lipschitz continuous. Show that \(X_\infty := \lim_{n\to\infty}X_n\) exists almost surely.</p> <p>(d) Show that \(f(x)-f(0)=\int^x_0 X_\infty(\omega)\,d\omega\) for all \(x\in[0,1].\) Conclude that \(f\) is differentiable almost everywhere.</p> </li> <li> <p>In this problem you are asked to give a proof of the Lebesgue differentiation theorem using martingales. Recall that the Lebesgue differentiation theorem says that for any locally integrable function \(f:\mathbb{R}\to\mathbb{R}\) we have \begin{equation} \lim_{r\to 0} \frac{1}{2r} \int_{(x-r,x+r)} f(y)\,dy = f(x) \quad \text{for almost every }x\in\mathbb{R}. \end{equation} Consider \((\Omega,\mathcal{F},\mathbb{P}) = ([0,1),\mathcal{B}([0,1)), \lambda)\) with \(A_{k,n}\) and \(\mathcal{F}_n\) defined as in the previous problem. Let \(f\in L^1([0,1))\) and define \(M_k(f) := \mathbb{E}(f\|\mathcal{F}_k).\)</p> <p>(a) Show that \((M_k(f))_{k=0}^\infty\) is an \((\mathcal{F}_n)\)-martingale and show that it converges almost surely to some \(M_\infty(f) \in L^1([0,1)).\)</p> <p>(b) Show that for any \(k=1,2,\ldots\), \(M_k(f)\) can be expressed as \begin{equation}M_k(f)(\omega) = \frac{1}{|I_\omega|}\int_{I_\omega}f(s)\,ds\quad\forall \omega\in [0,1)\end{equation} where \(I_\omega\) is the unique interval in \(\{ A_{m,k} : 1 \leq m \leq 2^{k} \}\) containing \(\omega.\) Hint: you are essentially asked to show that \(M_k(f) = \sum_{i=0}^{2^k-1} 1_{[i2^{-k}, (i+1)2^{-k})}2^k \int^{(i+1)2^{-k}}_{i2^{-k}}f(s)\,ds.\)</p> <p>(c) Show that for any \(g\in C([0,1])\), \(M_\infty(g)=g.\) Hint: use the uniform continuity of \(g.\)</p> <p>(d) Prove that \(M_\infty(f)=f\) almost surely. Conclude that the Lebesgue differentiation theorem holds.</p> </li> </ol>]]></content><author><name></name></author><category term="math"/><category term="math"/><category term="probability"/><category term="problems"/><summary type="html"><![CDATA[Here I give a list of seven (in my opinion) very cool and instructive exercises in probability. Only the basics of measure theoretic probability theory and martingales is needed. Most of these are assignment or exam exercises I encountered during my undergraduate studies. They are not supposed to be trivial, yet doable especially with the hints given.]]></summary></entry></feed>